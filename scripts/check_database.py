#!/usr/bin/env python3
"""
æ•°æ®åº“æŸ¥è¯¢è„šæœ¬
ç”¨äºéªŒè¯æ–‡æ¡£ç®¡ç†åŠŸèƒ½çš„æ­£ç¡®æ€§ï¼Œç›´æ¥æŸ¥è¯¢ChromaDBå’ŒSQLiteæ•°æ®åº“
"""

import os
import sys
import sqlite3
import json
from pathlib import Path
from typing import Dict, List, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

import chromadb
from backend.config import settings


class DatabaseChecker:
    """æ•°æ®åº“æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.chroma_client = None
        self.collection = None
        self.sqlite_path = None
        self.setup_connections()
    
    def setup_connections(self):
        """å»ºç«‹æ•°æ®åº“è¿æ¥"""
        try:
            # è¿æ¥ChromaDB
            self.chroma_client = chromadb.PersistentClient(
                path=settings.chroma_persist_directory
            )
            
            # è·å–é›†åˆ
            try:
                self.collection = self.chroma_client.get_collection(
                    name=settings.collection_name
                )
                print(f"âœ“ æˆåŠŸè¿æ¥åˆ°ChromaDBé›†åˆ: {settings.collection_name}")
            except Exception as e:
                print(f"âœ— ChromaDBé›†åˆä¸å­˜åœ¨: {e}")
                return
            
            # æŸ¥æ‰¾SQLiteæ•°æ®åº“æ–‡ä»¶
            storage_path = Path(settings.chroma_persist_directory)
            sqlite_files = list(storage_path.glob("*.sqlite3"))
            if sqlite_files:
                self.sqlite_path = sqlite_files[0]
                print(f"âœ“ æ‰¾åˆ°SQLiteæ•°æ®åº“: {self.sqlite_path}")
            else:
                print("âœ— æœªæ‰¾åˆ°SQLiteæ•°æ®åº“æ–‡ä»¶")
                
        except Exception as e:
            print(f"âœ— æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
    
    def check_chroma_data(self) -> Dict[str, Any]:
        """æ£€æŸ¥ChromaDBæ•°æ®"""
        if not self.collection:
            return {"error": "ChromaDBé›†åˆæœªè¿æ¥"}
        
        try:
            # è·å–æ‰€æœ‰æ•°æ®
            result = self.collection.get(include=["metadatas", "documents"])
            
            total_docs = len(result["ids"])
            
            # æŒ‰æ–‡ä»¶ååˆ†ç»„ç»Ÿè®¡
            file_stats = {}
            for i, doc_id in enumerate(result["ids"]):
                metadata = result["metadatas"][i] if result["metadatas"] else {}
                filename = metadata.get("filename", "æœªçŸ¥æ–‡ä»¶")
                
                if filename not in file_stats:
                    file_stats[filename] = {
                        "filename": filename,
                        "chunks": [],
                        "total_chunks": 0,
                        "file_size": metadata.get("file_size", 0),
                        "file_path": metadata.get("file_path", ""),
                        "file_modified": metadata.get("file_modified", "")
                    }
                
                file_stats[filename]["chunks"].append({
                    "id": doc_id,
                    "text_length": len(result["documents"][i]) if result["documents"] and result["documents"][i] else 0
                })
                file_stats[filename]["total_chunks"] += 1
            
            return {
                "total_documents": total_docs,
                "unique_files": len(file_stats),
                "files": file_stats
            }
            
        except Exception as e:
            return {"error": f"æŸ¥è¯¢ChromaDBå¤±è´¥: {e}"}
    
    def check_sqlite_data(self) -> Dict[str, Any]:
        """æ£€æŸ¥SQLiteæ•°æ®"""
        if not self.sqlite_path or not self.sqlite_path.exists():
            return {"error": "SQLiteæ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨"}
        
        try:
            conn = sqlite3.connect(self.sqlite_path)
            cursor = conn.cursor()
            
            # è·å–æ‰€æœ‰è¡¨
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table';")
            tables = [row[0] for row in cursor.fetchall()]
            
            table_info = {}
            for table in tables:
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                
                # è·å–è¡¨ç»“æ„
                cursor.execute(f"PRAGMA table_info({table})")
                columns = [col[1] for col in cursor.fetchall()]
                
                table_info[table] = {
                    "row_count": count,
                    "columns": columns
                }
            
            conn.close()
            
            return {
                "database_path": str(self.sqlite_path),
                "tables": table_info
            }
            
        except Exception as e:
            return {"error": f"æŸ¥è¯¢SQLiteå¤±è´¥: {e}"}
    
    def check_file_consistency(self) -> Dict[str, Any]:
        """æ£€æŸ¥æ–‡ä»¶ä¸€è‡´æ€§"""
        chroma_data = self.check_chroma_data()
        
        if "error" in chroma_data:
            return {"error": "æ— æ³•æ£€æŸ¥ä¸€è‡´æ€§ï¼ŒChromaDBæŸ¥è¯¢å¤±è´¥"}
        
        # æ£€æŸ¥dataç›®å½•ä¸­çš„æ–‡ä»¶
        data_path = Path(settings.data_dir)
        if not data_path.exists():
            return {"error": f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_path}"}
        
        txt_files = list(data_path.glob("*.txt"))
        disk_files = {f.name for f in txt_files}
        db_files = set(chroma_data["files"].keys())
        
        # æ‰¾å‡ºä¸ä¸€è‡´çš„æ–‡ä»¶
        only_on_disk = disk_files - db_files
        only_in_db = db_files - disk_files
        common_files = disk_files & db_files
        
        return {
            "disk_files": list(disk_files),
            "database_files": list(db_files),
            "only_on_disk": list(only_on_disk),
            "only_in_database": list(only_in_db),
            "common_files": list(common_files),
            "consistency_ok": len(only_on_disk) == 0 and len(only_in_db) == 0
        }
    
    def print_summary(self):
        """æ‰“å°æ•°æ®åº“æ‘˜è¦"""
        print("\n" + "="*60)
        print("æ•°æ®åº“çŠ¶æ€æ£€æŸ¥æŠ¥å‘Š")
        print("="*60)
        
        # ChromaDBæ•°æ®
        print("\nğŸ“Š ChromaDBæ•°æ®:")
        chroma_data = self.check_chroma_data()
        if "error" in chroma_data:
            print(f"  âœ— {chroma_data['error']}")
        else:
            print(f"  âœ“ æ€»æ–‡æ¡£å—æ•°: {chroma_data['total_documents']}")
            print(f"  âœ“ å”¯ä¸€æ–‡ä»¶æ•°: {chroma_data['unique_files']}")
            
            if chroma_data['files']:
                print("\n  ğŸ“ æ–‡ä»¶è¯¦æƒ…:")
                for filename, info in chroma_data['files'].items():
                    print(f"    â€¢ {filename}: {info['total_chunks']} å—")
        
        # SQLiteæ•°æ®
        print("\nğŸ—„ï¸ SQLiteæ•°æ®:")
        sqlite_data = self.check_sqlite_data()
        if "error" in sqlite_data:
            print(f"  âœ— {sqlite_data['error']}")
        else:
            print(f"  âœ“ æ•°æ®åº“è·¯å¾„: {sqlite_data['database_path']}")
            print(f"  âœ“ è¡¨æ•°é‡: {len(sqlite_data['tables'])}")
            
            for table, info in sqlite_data['tables'].items():
                print(f"    â€¢ {table}: {info['row_count']} è¡Œ")
        
        # æ–‡ä»¶ä¸€è‡´æ€§
        print("\nğŸ” æ–‡ä»¶ä¸€è‡´æ€§:")
        consistency = self.check_file_consistency()
        if "error" in consistency:
            print(f"  âœ— {consistency['error']}")
        else:
            if consistency['consistency_ok']:
                print("  âœ“ ç£ç›˜æ–‡ä»¶ä¸æ•°æ®åº“æ–‡ä»¶å®Œå…¨ä¸€è‡´")
            else:
                print("  âš ï¸ å‘ç°ä¸ä¸€è‡´:")
                if consistency['only_on_disk']:
                    print(f"    â€¢ ä»…åœ¨ç£ç›˜: {consistency['only_on_disk']}")
                if consistency['only_in_database']:
                    print(f"    â€¢ ä»…åœ¨æ•°æ®åº“: {consistency['only_in_database']}")
            
            print(f"  ğŸ“ ç£ç›˜æ–‡ä»¶æ•°: {len(consistency['disk_files'])}")
            print(f"  ğŸ—ƒï¸ æ•°æ®åº“æ–‡ä»¶æ•°: {len(consistency['database_files'])}")
        
        print("\n" + "="*60)
    
    def export_detailed_report(self, output_file: str = "database_report.json"):
        """å¯¼å‡ºè¯¦ç»†æŠ¥å‘Š"""
        report = {
            "timestamp": str(Path().cwd()),
            "chroma_data": self.check_chroma_data(),
            "sqlite_data": self.check_sqlite_data(),
            "consistency": self.check_file_consistency()
        }
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²å¯¼å‡ºåˆ°: {output_file}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” å¼€å§‹æ£€æŸ¥æ•°æ®åº“çŠ¶æ€...")
    
    checker = DatabaseChecker()
    checker.print_summary()
    
    # è¯¢é—®æ˜¯å¦å¯¼å‡ºè¯¦ç»†æŠ¥å‘Š
    try:
        export = input("\næ˜¯å¦å¯¼å‡ºè¯¦ç»†æŠ¥å‘Šåˆ°JSONæ–‡ä»¶? (y/N): ").strip().lower()
        if export in ['y', 'yes']:
            checker.export_detailed_report()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ æ£€æŸ¥å®Œæˆ")


if __name__ == "__main__":
    main()
